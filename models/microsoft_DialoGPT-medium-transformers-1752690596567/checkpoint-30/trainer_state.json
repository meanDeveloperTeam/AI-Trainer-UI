{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 30,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "grad_norm": 0.3699817955493927,
      "learning_rate": 0.0,
      "loss": 9.8057,
      "step": 1
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.39410796761512756,
      "learning_rate": 1e-05,
      "loss": 10.2158,
      "step": 2
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7360583543777466,
      "learning_rate": 2e-05,
      "loss": 9.5797,
      "step": 3
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.4077896177768707,
      "learning_rate": 3e-05,
      "loss": 10.149,
      "step": 4
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.4636783003807068,
      "learning_rate": 4e-05,
      "loss": 10.337,
      "step": 5
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4365098476409912,
      "learning_rate": 5e-05,
      "loss": 10.0533,
      "step": 6
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4458987712860107,
      "learning_rate": 4.8e-05,
      "loss": 11.9424,
      "step": 7
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.46518972516059875,
      "learning_rate": 4.600000000000001e-05,
      "loss": 10.5594,
      "step": 8
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.51522296667099,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 10.2343,
      "step": 9
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4325267970561981,
      "learning_rate": 4.2e-05,
      "loss": 9.6731,
      "step": 10
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.48666396737098694,
      "learning_rate": 4e-05,
      "loss": 9.5846,
      "step": 11
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.46845707297325134,
      "learning_rate": 3.8e-05,
      "loss": 10.4453,
      "step": 12
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.5005548596382141,
      "learning_rate": 3.6e-05,
      "loss": 10.2052,
      "step": 13
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.4964258372783661,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 10.1266,
      "step": 14
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.44598326086997986,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 9.7402,
      "step": 15
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.49735304713249207,
      "learning_rate": 3e-05,
      "loss": 10.3507,
      "step": 16
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5236795544624329,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 10.3207,
      "step": 17
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6533902287483215,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 10.284,
      "step": 18
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5334429740905762,
      "learning_rate": 2.4e-05,
      "loss": 9.7668,
      "step": 19
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5531551241874695,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 10.3013,
      "step": 20
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5140488743782043,
      "learning_rate": 2e-05,
      "loss": 9.9422,
      "step": 21
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.6509795784950256,
      "learning_rate": 1.8e-05,
      "loss": 10.5857,
      "step": 22
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6131579279899597,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 9.7316,
      "step": 23
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6937475800514221,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 9.9276,
      "step": 24
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6955445408821106,
      "learning_rate": 1.2e-05,
      "loss": 10.2245,
      "step": 25
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5594972968101501,
      "learning_rate": 1e-05,
      "loss": 10.0615,
      "step": 26
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5733664631843567,
      "learning_rate": 8.000000000000001e-06,
      "loss": 10.0047,
      "step": 27
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5903029441833496,
      "learning_rate": 6e-06,
      "loss": 9.5404,
      "step": 28
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.6244522333145142,
      "learning_rate": 4.000000000000001e-06,
      "loss": 10.2094,
      "step": 29
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6119122505187988,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 10.8637,
      "step": 30
    }
  ],
  "logging_steps": 1,
  "max_steps": 30,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 55866996817920.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
